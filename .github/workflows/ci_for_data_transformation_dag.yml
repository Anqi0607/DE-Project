name: CI for data transformation dag

on:
  pull_request:
    branches:
      - main
    paths:
      - 'airflow/**'
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      GOOGLE_APPLICATION_CREDENTIALS: /opt/airflow/.google/credentials/dev-sa-key.json

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Write GCP service account key
        run: |
          mkdir -p airflow/.google/credentials
          echo "${{ secrets.GCP_SA_KEY }}" > airflow/.google/credentials/dev-sa-key.json

      # Cache Docker layers to speed up the build process
      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache  # Cache location for docker layers
          key: ${{ runner.os }}-docker-${{ github.sha }}  # Cache key
          restore-keys: |
            ${{ runner.os }}-docker-  # Fallback cache key if specific key not found

      - name: Install Docker Compose
        run: |
          sudo curl -L "https://github.com/docker/compose/releases/download/$(curl -s https://api.github.com/repos/docker/compose/releases/latest | jq -r .tag_name)/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
          sudo chmod +x /usr/local/bin/docker-compose
          docker-compose --version  # Verify installation

      - name: Build Docker image
        run: |
          docker build --cache-from=ci-test-for-load-image -t ci-test-for-load-image -f docker/Dockerfile .

      - name: Run Docker compose
        run: |
          docker-compose -f docker/docker-compose.yml up -d

      - name: Run unit tests in Airflow container
        run: |
          docker exec docker-airflow-worker-1 sh -c "export PYTHONPATH='/opt/airflow/scripts:$PYTHONPATH' && pytest /opt/airflow/tests/unit/test_load_to_bucket.py"
